{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR NAMES HERE**\n",
    "\n",
    "Fall 2023\n",
    "\n",
    "CS 343: Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 15:02:22.146236: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "plt.show()\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "# Automatically reload external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow install test\n",
    "\n",
    "*Sanity check that Tensorflow is installed correctly:*\n",
    "\n",
    "Executing the following cell should print 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "tf.print(tf.reduce_sum([tf.constant(1), tf.constant(2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 | Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implement ConvNet4 in TensorFlow\n",
    "\n",
    "Construct the familiar ConvNet4 neural network architecture from last project in TensorFlow's high level `Keras::Sequential` API. Also like your last project, train on the STL-10 training set and test on the STL-10 training set.\n",
    "\n",
    "### 1a. Use the high level `Keras::Sequential` API in Tensorflow 2 to implement the architecture of ConvNet4 from the last project. Train and test your network on the STL-10 dataset. \n",
    "\n",
    "**Goal:** Achieve ≥ 50% on either the validation set or test set. *For our purposes, getting ≥ 50% validation accuracy at any point during training is enough (i.e. doesn't need to be at the very end of training).*\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- You should use the usual STL-10 data acquisition and preprocessing code from your last project. You can use the default split, or modify it yourself.\n",
    "- You don't need to do a hyperparameter search. Values that worked on the CNN project should get you in the ballpark here. The goal is to show that you know how to put together a `keras::Sequential` model and have it work successfully.\n",
    "- You may have to tweak the hyperparameters by hand a little (number of epochs, weight initialization method, number of hidden units, etc.) to hit your accuracy target, but it should not take too much effort.\n",
    "- TensorFlow needs the RGB color channel AFTER the spatial dimensions. For example: (32, 32, 3), not (3, 32, 32). You may therefore need to slightly modify the preprocesssing pipeline for this project.\n",
    "\n",
    "#### Keras Sequential workflow\n",
    "\n",
    "Recall the `Keras::Sequential` common workflow:\n",
    "\n",
    "- Build structure of network with `keras::Sequential`.\n",
    "- Compile network with your choice of optimizer, loss, and metrics.\n",
    "- Fit the model (remembering to pass in the appropriate training and validation sets). This results a history object that can be used to examine training/validation accuracy and loss.\n",
    "- Evaluate the model on the test set. This returns test loss and accuracy.\n",
    "\n",
    "#### Helpful documentation\n",
    "\n",
    "These documentation pages should be helpful:\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/Model#summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_stl10_dataset\n",
    "from preprocess_data import load_stl10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading stl10_binary.tar.gz 13.82%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gordondoore/Documents/GitHub/CH343/project4/transfer_learning.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gordondoore/Documents/GitHub/CH343/project4/transfer_learning.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#get data and split it\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gordondoore/Documents/GitHub/CH343/project4/transfer_learning.ipynb#X60sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m x_train, y_train, x_test, y_test, x_val, y_val, x_dev, y_dev \u001b[39m=\u001b[39m load_stl10(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gordondoore/Documents/GitHub/CH343/project4/transfer_learning.ipynb#X60sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     n_train_samps\u001b[39m=\u001b[39;49m\u001b[39m4398\u001b[39;49m, n_test_samps\u001b[39m=\u001b[39;49m\u001b[39m400\u001b[39;49m, n_valid_samps\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, n_dev_samps\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, scale_fact\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/GitHub/CH343/project4/preprocess_data.py:101\u001b[0m, in \u001b[0;36mload_stl10\u001b[0;34m(n_train_samps, n_test_samps, n_valid_samps, n_dev_samps, scale_fact)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_stl10\u001b[39m(n_train_samps\u001b[39m=\u001b[39m\u001b[39m3500\u001b[39m, n_test_samps\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, n_valid_samps\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, n_dev_samps\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, scale_fact \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m):\n\u001b[1;32m     84\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Automates the process of:\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m    - loading in the STL-10 dataset and labels\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39m    - preprocessing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39m    y_dev (development labels)\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     stl_imgs, stl_labels \u001b[39m=\u001b[39m load_stl10_dataset\u001b[39m.\u001b[39;49mload(scale_fact \u001b[39m=\u001b[39;49m scale_fact)\n\u001b[1;32m    102\u001b[0m     stl_imgs, stl_labels \u001b[39m=\u001b[39m preprocess_stl(stl_imgs, stl_labels)\n\u001b[1;32m    103\u001b[0m     \u001b[39mreturn\u001b[39;00m create_splits(stl_imgs, stl_labels, n_train_samps, n_test_samps, n_valid_samps, n_dev_samps)\n",
      "File \u001b[0;32m~/Documents/GitHub/CH343/project4/load_stl10_dataset.py:216\u001b[0m, in \u001b[0;36mload\u001b[0;34m(save_imgs_to_disk, cache_binaries_to_disk, scale_fact)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[39mreturn\u001b[39;00m images, labels\n\u001b[1;32m    215\u001b[0m \u001b[39m# download data if needed\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m download_and_extract(DATA_URL, DATA_DIR, DATA_PATH, LABEL_PATH)\n\u001b[1;32m    218\u001b[0m \u001b[39m# Read in the whole dataset and labels\u001b[39;00m\n\u001b[1;32m    219\u001b[0m images \u001b[39m=\u001b[39m read_all_images(DATA_PATH)\n",
      "File \u001b[0;32m~/Documents/GitHub/CH343/project4/load_stl10_dataset.py:109\u001b[0m, in \u001b[0;36mdownload_and_extract\u001b[0;34m(DATA_URL, DATA_DIR, DATA_PATH, LABEL_PATH)\u001b[0m\n\u001b[1;32m    107\u001b[0m         sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39mDownloading \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m%%\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (filename, \u001b[39mfloat\u001b[39m(count \u001b[39m*\u001b[39m block_size) \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(total_size)\u001b[39m*\u001b[39m\u001b[39m100.0\u001b[39m))\n\u001b[1;32m    108\u001b[0m         sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mflush()\n\u001b[0;32m--> 109\u001b[0m     filepath, _ \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39;49murlretrieve(DATA_URL, filepath, reporthook\u001b[39m=\u001b[39;49m_progress)\n\u001b[1;32m    110\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mDownloaded\u001b[39m\u001b[39m'\u001b[39m, filename)\n\u001b[1;32m    112\u001b[0m \u001b[39m# Extract the tar file only if the extracted files do not already exist\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/x43/lib/python3.11/urllib/request.py:277\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    275\u001b[0m             blocknum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    276\u001b[0m             \u001b[39mif\u001b[39;00m reporthook:\n\u001b[0;32m--> 277\u001b[0m                 reporthook(blocknum, bs, size)\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m size \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m read \u001b[39m<\u001b[39m size:\n\u001b[1;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m ContentTooShortError(\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mretrieval incomplete: got only \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m out of \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m bytes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[39m%\u001b[39m (read, size), result)\n",
      "File \u001b[0;32m~/Documents/GitHub/CH343/project4/load_stl10_dataset.py:108\u001b[0m, in \u001b[0;36mdownload_and_extract.<locals>._progress\u001b[0;34m(count, block_size, total_size)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_progress\u001b[39m(count, block_size, total_size):\n\u001b[1;32m    107\u001b[0m     sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39mDownloading \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m%%\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (filename, \u001b[39mfloat\u001b[39m(count \u001b[39m*\u001b[39m block_size) \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(total_size)\u001b[39m*\u001b[39m\u001b[39m100.0\u001b[39m))\n\u001b[0;32m--> 108\u001b[0m     sys\u001b[39m.\u001b[39;49mstdout\u001b[39m.\u001b[39;49mflush()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/x43/lib/python3.11/site-packages/ipykernel/iostream.py:578\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpub_thread\u001b[39m.\u001b[39mschedule(evt\u001b[39m.\u001b[39mset)\n\u001b[1;32m    577\u001b[0m     \u001b[39m# and give a timeout to avoid\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt\u001b[39m.\u001b[39;49mwait(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mflush_timeout):\n\u001b[1;32m    579\u001b[0m         \u001b[39m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    580\u001b[0m         \u001b[39m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[1;32m    581\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIOStream.flush timed out\u001b[39m\u001b[39m\"\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39m__stderr__)\n\u001b[1;32m    582\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/x43/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    623\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/x43/lib/python3.11/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#get data and split it\n",
    "x_train, y_train, x_test, y_test, x_val, y_val, x_dev, y_dev = load_stl10(\n",
    "    n_train_samps=4398, n_test_samps=400, n_valid_samps=200, n_dev_samps=2, scale_fact=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network has following structure: \n",
    "\n",
    "#convolution, max-pooling, dense, denseout\n",
    "def Conv4_Keras(input_shape=(3, 32, 32), n_kers=(32,), ker_sz=(7,7), dense_interior_units=(100,), pool_size=(2,2), pooling_strides=(2,2), n_classes=10, wt_scale=1e-3, reg=0.001):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape = input_shape))\n",
    "    model.add(tf.keras.layers.Conv2D(filters = n_kers[0], kernel_size = ker_sz, padding = 'same', activation = 'relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size = pool_size, strides = pooling_strides))\n",
    "    model.add(tf.keras.layers.Dense(units = dense_interior_units[0],activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dense(units = n_classes, activation = 'softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = Conv4_Keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
    "                       tf.keras.metrics.FalseNegatives()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, validation_split = 0.05, batch_size=100, n_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Make 2 \"high quality\" plots showing the following\n",
    "\n",
    "- Training and validation accuracy (y axis) over training epochs (x axis).\n",
    "- Training and validation loss (y axis) over epochs (x axis).\n",
    "\n",
    "A high quality plot consists of:\n",
    "- A useful title\n",
    "- X and Y axis labels\n",
    "- A legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Visualize predictions\n",
    "\n",
    "Make a 5x5 grid of the first 25 images in the test dataset. Label each with the predicted class label string (English label, not an int code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d. Questions\n",
    "\n",
    "**Question 1:** What accuracy do you get on the STL-10 test set? Briefly summarize the hyperparameters that you used to obtain this result.\n",
    "\n",
    "**Question 2:** How do the loss and accurary results compare to the CNN project?\n",
    "\n",
    "**Question 3:** Identify a few misclassifications. Is there a discernable pattern?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 1:**\n",
    "\n",
    "**Answer 2:** \n",
    "\n",
    "**Answer 3:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Transfer learning\n",
    "\n",
    "Here you will use Tensorflow 2 to download the pre-trained MobileNetV2 network (you may also use another network like InceptionV3, VGG19, or EfficientNet, but MobileNetV2 likely will run noticeably faster on your machine). We will use transfer learning to accelerate training to solve a novel problem: **the binary classification task of discriminating whether an image is of a hotdog or not.**\n",
    "\n",
    "### Overview\n",
    "\n",
    "- Remove the output layer, add a new Dense output layer.\n",
    "- Freeze (disable) training on all non-output layers.\n",
    "- Train the last layer on a food dataset. Assess performance. Plot some example images and their classification below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Download and load in hotdot image dataset\n",
    "\n",
    "Download the **food dataset** from the project website, copy it into a `data` subfolder in your project directory.\n",
    "\n",
    "Run the below code to load in the hot-dog-or-not dataset. Check the shapes to ensure everything is loaded in correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_base_dir='data/hot-dog-not-hot-dog/numpy/'\n",
    "\n",
    "hotdog_train_x = np.load(os.path.join(ds_base_dir, 'train_x.npy'))\n",
    "hotdog_train_y = np.load(os.path.join(ds_base_dir, 'train_y.npy'))\n",
    "hotdog_test_x = np.load(os.path.join(ds_base_dir, 'test_x.npy'))\n",
    "hotdog_test_y = np.load(os.path.join(ds_base_dir, 'test_y.npy'))\n",
    "\n",
    "print(f'Training hotdog split shape: {hotdog_train_x.shape}. Should be (16000, 96, 96, 3)')\n",
    "print(f'Test hotdog split shape: {hotdog_test_x.shape}. Should be (4000, 96, 96, 3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Normalize hotdog dataset\n",
    "\n",
    "Standardize both the train and test dataset according to the **same statistics** computed from the **training set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Create hotdog validation set\n",
    "\n",
    "Set aside the last 20% of the training set as the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(f'Validation hotdog split shape: {hotdog_val_x.shape}. Should be (3200, 96, 96, 3)')\n",
    "print(f'Training hotdog split shape: {hotdog_train_x.shape}. Should be (12800, 96, 96, 3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. Load in pre-trained MobileNetV2 network.\n",
    "\n",
    "Load in a pre-trained MobileNetV2 network (look up constructor in [tf.keras.applications](https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2/MobileNetV2) or look at the tutorial from class) and set it to a variable called `model`. Remember to make the network not trainable. Calling the `summary()` method on the network object should show you a table with many rows. The top and bottom rows should be:\n",
    "\n",
    "\n",
    "    input_1 (InputLayer)           [(None, 96, 96, 3)]  0           []                                            \n",
    "    __________________________________________________________________________________________________\n",
    "    out_relu (ReLU)                (None, 3, 3, 1280)   0           ['Conv_1_bn[0][0]']              \n",
    "                                                                                                  \n",
    "==================================================================================================\n",
    "\n",
    "and you should see the following at the bottom:\n",
    "\n",
    "    Total params: 2,257,984\n",
    "    Trainable params: 0\n",
    "    Non-trainable params: 2,257,984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2e. Create augmented model\n",
    "\n",
    "Create a new `keras::Sequential` augmented model with an output layer that has the correct number of units to deal with the hot-dog or not problem with your choice of optimizer, an appropriate loss, and metric(s).\n",
    "\n",
    "#### Helpful links\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2f. Questions\n",
    "\n",
    "**Question 4:** What is the accuracy and loss for the network with the untrained output layer on the test set? Explain why you got the accuracy value that you did.\n",
    "\n",
    "**Question 5:** Briefly defend your choice of number of units in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 4:** \n",
    "\n",
    "**Answer 5:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2g. Fit the augmented model on the hotdog training data\n",
    "\n",
    "Setting the verbose optional parameter to 2 will give you helpful printouts of performance on the validation set as it completes every epoch of training.\n",
    "\n",
    "#### Training goal\n",
    "\n",
    "You should aim to achieve at least 85% accuracy on the validation set. If everything is set up properly, you should only need to train for a very small number of epochs.\n",
    "\n",
    "\n",
    "#### Note\n",
    "\n",
    "If training time is taking much more than a few minutes per epoch on your computer, you could try reducing the number of data samples in train and validation. For example, by default train `N = 12800`. Try `N = 6400` instead. You could do the same for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2h. Plot hotdog results\n",
    "\n",
    "Produce 2 high quality plots showing the following:\n",
    "\n",
    "- Training and validation loss over epoch.\n",
    "- Training and validation accuracy over epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2i. Visualize predictions on test set\n",
    "\n",
    "Use your trained hotdog classifier to get the predicted classes for the first 25 **test set** samples. Then create a 5x5 grid of the first 25 test samples and label each with the predicted class string (English label, not an int code).\n",
    "- If the prediction is correct, color the label *blue*.\n",
    "- If the prediction is incorrect, color the label *red*.\n",
    "\n",
    "**Note:**\n",
    "- Depending on how you get the network predictions, TensorFlow may give you a vector of class probabilities. This could be shape `(N, 2)` or `(N,)`, depending on the output layer activation function that you used. Remember that if you have these probabilities, you need to recover the predicted class index (e.g. `0`, `1`) before you can label your plots.\n",
    "- If `imshow` gives you warnings about clipping, check the range of the test samples. If your max is slightly higher than 1, either ignore the warning or divide by the max. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2j. Questions\n",
    "\n",
    "**Question 6:** What is the best accuracy that you are able to achieve on the test set? Briefly summarize the hyperparameters that were used in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 6:** \n",
    "\n",
    "No points off for lower accuracy, but something less than 70% might be an indicator that something is wrong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
