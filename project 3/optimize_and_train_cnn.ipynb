{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR NAMES HERE**\n",
    "\n",
    "Fall 2023\n",
    "\n",
    "CS343: Neural Networks\n",
    "\n",
    "Project 3: Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.show()\n",
    "plt.style.use(['seaborn-colorblind', 'seaborn-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=7)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "**Make sure any debug printouts do not appear if `verbose=False`!**\n",
    "\n",
    "This week, you will test your CNN on the STL-10 dataset! The last step before you can do this is implementing an optimizer to update your network weights during gradient descent. You will implement a few and compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Implement weight optimizers for gradient descent\n",
    "\n",
    "To change the weights during training, we need an optimization algorithm to have our loss decrease over epochs as we learn the structure of the input patterns. Until now, we used **Stochastic gradient descent (SGD)**, which is the simplest algorithm. You will implement 3 popular algorithms:\n",
    "\n",
    "- `SGD` (stochastic gradient descent)\n",
    "- `SGD_Momentum` (stochastic gradient descent with momentum)\n",
    "- `Adam` (Adaptive Moment Estimation)\n",
    "\n",
    "Implement each of these according to the update equations (the `update_weights()` in each subclass in `optimizer.py`). Let's use $w_t$ in the math below to represent the weights in a layer at time step $t$, $dw$ to represent the gradient of the weights in a layer, and $\\eta$ represent the learning rate. We use vectorized notation below (update applies to all weights element-wise). Then:\n",
    "\n",
    "**SGD**: \n",
    "\n",
    "$w_{t} = w_{t-1} - \\eta \\times dw$\n",
    "\n",
    "**SGD (momentum)**:\n",
    "\n",
    "$v_{t} = m \\times v_{t-1} - \\eta \\times dw$\n",
    "\n",
    "$w_{t} = w_{t-1} + v_t$\n",
    "\n",
    "where $v_t$ is called the `velocity` at time $t$. At the first time step (0), velocity should be set to all zeros and have the same shape as $w$. $m$ is a constant that determines how much of the gradient obtained on the previous time step should factor into the weight update for the current time step.\n",
    "\n",
    "\n",
    "**Adam**:\n",
    "\n",
    "$v_{t} = \\beta_1 \\times v_{t-1} + (1 - \\beta_1)\\times dw$\n",
    "\n",
    "$p_{t} = \\beta_2 \\times p_{t-1} + (1 - \\beta_2)\\times dw^2$\n",
    "\n",
    "$vc = v_{t} / \\left (1-(\\beta_1^t) \\right )$\n",
    "\n",
    "$pc = p_{t} / \\left (1-(\\beta_2^t) \\right )$\n",
    "\n",
    "$w_{t} = w_{t-1} - \\left ( \\eta \\times vc \\right ) / \\left ( \\sqrt(pc) + \\epsilon \\right ) $\n",
    "\n",
    "\n",
    "Like SGD (momentum), Adam records momentum terms $v$ and $p$. At time step 0, you should initialize them to zeros in an array equal in size to the weights. $vc$ and $pc$ are variables computed on each time step. The remaining quantities are constants. Note that $t$ keeps track of the integer time step, and needs to be incremented on each update. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Test SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: Wts after 1 iter [-3.1764052 -2.0400157 -1.0978738 -0.2240893  0.8132442  2.0977278]\n",
      "SGD: Wts after 2 iter [-3.3528105 -2.0800314 -1.1957476 -0.4481786  0.6264884  2.1954556]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "wts = np.arange(-3, 3, dtype=np.float64)\n",
    "d_wts = np.random.randn(len(wts))\n",
    "\n",
    "optimizer = SGD()\n",
    "optimizer.prepare(wts, d_wts)\n",
    "\n",
    "new_wts_1 = optimizer.update_weights(verbose = True)\n",
    "new_wts_2 = optimizer.update_weights()\n",
    "\n",
    "print(f'SGD: Wts after 1 iter {new_wts_1}')\n",
    "print(f'SGD: Wts after 2 iter {new_wts_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output should be:\n",
    "\n",
    "    SGD: Wts after 1 iter [-3.1764052 -2.0400157 -1.0978738 -0.2240893  0.8132442  2.0977278]\n",
    "    SGD: Wts after 2 iter [-3.3528105 -2.0800314 -1.1957476 -0.4481786  0.6264884  2.1954556]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Test SGD_Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD M: Wts after 1 iter\n",
      "[[ 1.6879486  0.3879897  0.9343517  2.2075258]\n",
      " [ 1.7181501 -0.9567621  0.9187816 -0.0659476]\n",
      " [ 0.1520801  0.3452366  0.0576     1.52849  ]]\n",
      "SGD M: Wts after 2 iter\n",
      "[[ 1.5661825  0.3685217  0.8633335  2.1541379]\n",
      " [ 1.4790974 -0.9239367  0.8686908  0.0707077]\n",
      " [ 0.5605585  0.2406577 -0.0807098  1.6472364]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "wts = np.random.randn(3, 4)\n",
    "d_wts = np.random.randn(3, 4)\n",
    "\n",
    "optimizer = SGD_Momentum(lr=0.1, m=0.6)\n",
    "optimizer.prepare(wts, d_wts)\n",
    "\n",
    "new_wts_1 = optimizer.update_weights()\n",
    "new_wts_2 = optimizer.update_weights()\n",
    "\n",
    "print(f'SGD M: Wts after 1 iter\\n{new_wts_1}')\n",
    "print(f'SGD M: Wts after 2 iter\\n{new_wts_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output should be:\n",
    "\n",
    "    SGD M: Wts after 1 iter\n",
    "    [[ 1.6879486  0.3879897  0.9343517  2.2075258]\n",
    "     [ 1.7181501 -0.9567621  0.9187816 -0.0659476]\n",
    "     [ 0.1520801  0.3452366  0.0576     1.52849  ]]\n",
    "    SGD M: Wts after 2 iter\n",
    "    [[ 1.5661825  0.3685217  0.8633335  2.1541379]\n",
    "     [ 1.4790974 -0.9239367  0.8686908  0.0707077]\n",
    "     [ 0.5605585  0.2406577 -0.0807098  1.6472364]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Test Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam: Wts after 1 iter\n",
      "[[ 1.6640523  0.3001572  0.878738   2.1408932]\n",
      " [ 1.767558  -0.8772779  0.8500884 -0.0513572]\n",
      " [-0.0032189  0.3105985  0.0440436  1.5542735]]\n",
      "Adam: Wts after 2 iter\n",
      "[[ 1.5640523  0.2001572  0.778738   2.0408932]\n",
      " [ 1.667558  -0.7772779  0.7500884  0.0486428]\n",
      " [ 0.0967811  0.2105985 -0.0559564  1.6542735]]\n",
      "Adam: Wts after 3 iter\n",
      "[[ 1.4640523  0.1001572  0.678738   1.9408932]\n",
      " [ 1.567558  -0.6772779  0.6500884  0.1486428]\n",
      " [ 0.1967811  0.1105985 -0.1559564  1.7542735]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "wts = np.random.randn(3, 4)\n",
    "d_wts = np.random.randn(3, 4)\n",
    "\n",
    "optimizer = Adam(lr=0.1)\n",
    "optimizer.prepare(wts, d_wts)\n",
    "\n",
    "new_wts_1 = optimizer.update_weights()\n",
    "new_wts_2 = optimizer.update_weights()\n",
    "new_wts_3 = optimizer.update_weights()\n",
    "\n",
    "print(f'Adam: Wts after 1 iter\\n{new_wts_1}')\n",
    "print(f'Adam: Wts after 2 iter\\n{new_wts_2}')\n",
    "print(f'Adam: Wts after 3 iter\\n{new_wts_3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output should be:\n",
    "\n",
    "    Adam: Wts after 1 iter\n",
    "    [[ 1.6640523  0.3001572  0.878738   2.1408932]\n",
    "     [ 1.767558  -0.8772779  0.8500884 -0.0513572]\n",
    "     [-0.0032189  0.3105985  0.0440436  1.5542735]]\n",
    "    Adam: Wts after 2 iter\n",
    "    [[ 1.5640523  0.2001572  0.778738   2.0408932]\n",
    "     [ 1.667558  -0.7772779  0.7500884  0.0486428]\n",
    "     [ 0.0967811  0.2105985 -0.0559564  1.6542735]]\n",
    "    Adam: Wts after 3 iter\n",
    "    [[ 1.4640523  0.1001572  0.678738   1.9408932]\n",
    "     [ 1.567558  -0.6772779  0.6500884  0.1486428]\n",
    "     [ 0.1967811  0.1105985 -0.1559564  1.7542735]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Write network training methods\n",
    "\n",
    "Implement methods in `network.py` to actually train the network, using all the building blocks that you have created. The methods to implement are:\n",
    "\n",
    "- `predict`\n",
    "- `fit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Overfitting a convolutional neural network\n",
    "\n",
    "Usually we try to prevent overfitting, but we can use it as a valuable debugging tool to test out a complex backprop-based neural network. Assuming everything is working, it is almost always the case that we should be able to overfit a tiny dataset with a huge model with tons of parameters (i.e. your CNN). You will use this strategy to verify that your network is working.\n",
    "\n",
    "Let's use a small amount of real data from STL-10 to perform the overfitting test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7a. Move `load_stl10_dataset` and `preprocess_data.py` from the MLP project\n",
    "\n",
    "Make the one following change in `preprocess_data.py`:\n",
    "\n",
    "- In `preprocess_stl`, Re-arrange dimensions of `imgs` so that when it is returned, `shape=(Num imgs, RGB color chans, height, width)` (No longer flatten non-batch dimensions)\n",
    "- In `load_stl10`, add an optional parameter to the function `scale_fact=3`, which specifies the factor by which to downscale the STL-10 images. The default (`scale_fact=3`) reduces the resolution from 96x96 to 32x32. Achieve this downscaling by passing along the optional parameter value when the `load` function in `load_stl10_dataset.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_stl10_dataset\n",
    "import preprocess_data\n",
    "from network import ConvNet4\n",
    "import optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b. Load in STL-10 at 16x16 resolution\n",
    "\n",
    "If you don't want to wait for STL-10 to download from the internet and resize, copy over your data and numpy folders from your MLP project.\n",
    "\n",
    "**Note:** The different train/test split here won't work if you hard coded the proportions in your `create_splits` implementation! *This isn't catastrophic, it just means that it will take longer to compute accuracy on the validation set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images are: (5000, 96, 96, 3)\n",
      "Labels are: (5000,)\n",
      "Resizing 5000 images to 16x16..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Saving Numpy arrays the images and labels to ./numpy...Done!\n",
      "Train data shape:  (4578, 3, 16, 16)\n",
      "Train labels shape:  (4578,)\n",
      "Test data shape:  (400, 3, 16, 16)\n",
      "Test labels shape:  (400,)\n",
      "Validation data shape:  (2, 3, 16, 16)\n",
      "Validation labels shape:  (2,)\n",
      "dev data shape:  (20, 3, 16, 16)\n",
      "dev labels shape:  (20,)\n"
     ]
    }
   ],
   "source": [
    "# Download the STL-10 dataset from the internet, convert it to Numpy ndarray, resize to 16x16\n",
    "# cache it locally on your computer for faster loading next time.\n",
    "load_stl10_dataset.purge_cached_dataset()\n",
    "# preprocess and create splits\n",
    "x_train, y_train, x_test, y_test, x_val, y_val, x_dev, y_dev = preprocess_data.load_stl10(\n",
    "    n_train_samps=4578, n_test_samps=400, n_valid_samps=2, n_dev_samps=20, scale_fact=6)\n",
    "\n",
    "print ('Train data shape: ', x_train.shape)\n",
    "print ('Train labels shape: ', y_train.shape)\n",
    "print ('Test data shape: ', x_test.shape)\n",
    "print ('Test labels shape: ', y_test.shape)\n",
    "print ('Validation data shape: ', x_val.shape)\n",
    "print ('Validation labels shape: ', y_val.shape)\n",
    "print ('dev data shape: ', x_dev.shape)\n",
    "print ('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7c. Train and overfit the network on a small STL-10 sample with each optimizer\n",
    "\n",
    "#### Goal\n",
    "\n",
    "If your network works, you should see a drop in loss over epochs to 0 from the initial value of ~2.3.\n",
    "\n",
    "#### Todo\n",
    "\n",
    "In 3 seperate cells below\n",
    "\n",
    "- Create 3 different `ConvNet4` networks.\n",
    "- Compile each with a different optimizer (i.e. each net uses a different optimizer).\n",
    "- Train each on the **dev** set and validate on the tiny validation set (we don't care about out-of-training-set performance here).\n",
    "\n",
    "You will be making plots demonstrating the overfitting for each optimizer below. **You should train the nets with the same number of epochs such that at least 2/3 of them clearly show loss convergence to a small value; one optimizer may not converge yet, and that's ok**. Cut off the simulations based on the 2/3 that do converge.\n",
    "\n",
    "#### Guidelines\n",
    "\n",
    "- Weight scales and learning rates of `1e-2` should work well.\n",
    "- Start by testing the Adam optimizer.\n",
    "- Remember that the input shape is (3, 16, 16). You need to specify this to the network constructor.\n",
    "- The hyperparameters are up to you, though I wouldn't recommend a batch size that is too small (close to 1), otherwise it may be tricky to see whether the loss is actually decreasing on average.\n",
    "- Decreasing `acc_freq` will make the `fit` function evaluate the training and validation accuracy more often. This is a computationally intensive process, so small values come with an increase in training time. On the other hand, checking the accuracy too infrequently means you won't know whether the network is trending toward overfitting the training data, which is what you're checking for.\n",
    "- Each training session takes ~15 mins on my laptop.\n",
    "\n",
    "#### Caveat emptor\n",
    "\n",
    "Training convolutional networks is notoriously computationally intensive. If you experiment with hyperparameters, each training session may take several hours.\n",
    "\n",
    "- Use the loss/accuracy print outs to quickly gauge whether your hyperparameter choices are getting your network to decrease in loss.\n",
    "- Monitor print outs and interrupt the Jupyter kernel if things are not trending in the right direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for 0th iteration: 4.137447834014893 seconds\n",
      "projected time to finish: 5.5165971120198565 minutes\n",
      "iterations number: 0 ------- loss:  2.2551810918127875\n",
      "train accuracy:  0.15\n",
      "validation accuracy:  0.0\n",
      "iterations number: 10 ------- loss:  1.581216638000914\n",
      "train accuracy:  0.6\n",
      "validation accuracy:  0.0\n",
      "iterations number: 20 ------- loss:  0.5567092529796581\n",
      "train accuracy:  0.8\n",
      "validation accuracy:  1.0\n",
      "iterations number: 30 ------- loss:  0.24704809677065348\n",
      "train accuracy:  0.7\n",
      "validation accuracy:  0.0\n",
      "iterations number: 40 ------- loss:  0.21262154345764794\n",
      "train accuracy:  0.85\n",
      "validation accuracy:  0.5\n",
      "iterations number: 50 ------- loss:  0.09122181566845378\n",
      "train accuracy:  1.0\n",
      "validation accuracy:  1.0\n",
      "iterations number: 60 ------- loss:  0.031022213166552945\n",
      "train accuracy:  1.0\n",
      "validation accuracy:  0.5\n",
      "iterations number: 70 ------- loss:  0.005186026426209075\n",
      "train accuracy:  1.0\n",
      "validation accuracy:  0.5\n",
      "final loss:  0.003994653193313512\n",
      "final train accuracy  1.0\n"
     ]
    }
   ],
   "source": [
    "# Adam\n",
    "adam_ConvNet4 = ConvNet4(input_shape = (3,16,16), wt_scale = 1e-2)\n",
    "adam_ConvNet4.compile('adam')\n",
    "adam_ConvNet4.fit(x_dev, y_dev, x_val, y_val,acc_freq=10, print_every=10, mini_batch_sz = 20, n_epochs = 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for 0th iteration: 3.7065999507904053 seconds\n",
      "projected time to finish: 4.94213326772054 minutes\n",
      "iterations number: 0 ------- loss:  2.6824520202891122\n",
      "train accuracy:  0.15\n",
      "validation accuracy:  0.5\n",
      "iterations number: 10 ------- loss:  1.9241967759479441\n",
      "train accuracy:  0.35\n",
      "validation accuracy:  0.5\n",
      "iterations number: 20 ------- loss:  1.2727854271032635\n",
      "train accuracy:  0.6\n",
      "validation accuracy:  0.5\n",
      "iterations number: 30 ------- loss:  0.4497527082401536\n",
      "train accuracy:  0.85\n",
      "validation accuracy:  0.5\n",
      "iterations number: 40 ------- loss:  1.3479042025623702\n",
      "train accuracy:  0.4\n",
      "validation accuracy:  0.5\n",
      "iterations number: 50 ------- loss:  3.4650924937296743\n",
      "train accuracy:  0.45\n",
      "validation accuracy:  0.5\n",
      "iterations number: 60 ------- loss:  0.8420959054216692\n",
      "train accuracy:  0.65\n",
      "validation accuracy:  0.5\n",
      "iterations number: 70 ------- loss:  0.28540394120939955\n",
      "train accuracy:  0.8\n",
      "validation accuracy:  0.5\n",
      "final loss:  0.06795325880147372\n",
      "final train accuracy  0.95\n"
     ]
    }
   ],
   "source": [
    "# SGD-M\n",
    "sgdm_ConvNet4 = ConvNet4(input_shape = (3,16,16), wt_scale = 1e-2)\n",
    "sgdm_ConvNet4.compile('sgd_m')\n",
    "sgdm_ConvNet4.fit(x_dev, y_dev, x_val, y_val,acc_freq=10, print_every=10, mini_batch_sz = 20, n_epochs = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for 0th iteration: 4.294498682022095 seconds\n",
      "projected time to finish: 5.725998242696126 minutes\n",
      "iterations number: 0 ------- loss:  2.1782544639875208\n",
      "train accuracy:  0.15\n",
      "validation accuracy:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gordondoore/Documents/GitHub/CH343/project 3/layer.py:464: RuntimeWarning: invalid value encountered in multiply\n",
      "  d_wts = np.reshape(self.input, (self.input.shape[0], np.prod(self.input.shape[1:]))).T @ d_upstream + self.reg*self.wts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations number: 10 ------- loss:  nan\n",
      "train accuracy:  0.0\n",
      "validation accuracy:  0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gordondoore/Documents/GitHub/CH343/project 3/optimize_and_train_cnn.ipynb Cell 25\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gordondoore/Documents/GitHub/CH343/project%203/optimize_and_train_cnn.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sgd_ConvNet4 \u001b[39m=\u001b[39m ConvNet4(input_shape \u001b[39m=\u001b[39m (\u001b[39m3\u001b[39m,\u001b[39m16\u001b[39m,\u001b[39m16\u001b[39m), wt_scale \u001b[39m=\u001b[39m \u001b[39m1e-2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gordondoore/Documents/GitHub/CH343/project%203/optimize_and_train_cnn.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sgd_ConvNet4\u001b[39m.\u001b[39mcompile(\u001b[39m'\u001b[39m\u001b[39msgd\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gordondoore/Documents/GitHub/CH343/project%203/optimize_and_train_cnn.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sgd_ConvNet4\u001b[39m.\u001b[39;49mfit(x_dev, y_dev, x_val, y_val,acc_freq\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, print_every\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, mini_batch_sz \u001b[39m=\u001b[39;49m \u001b[39m20\u001b[39;49m, n_epochs \u001b[39m=\u001b[39;49m \u001b[39m80\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/GitHub/CH343/project 3/network.py:120\u001b[0m, in \u001b[0;36mNetwork.fit\u001b[0;34m(self, x_train, y_train, x_validate, y_validate, mini_batch_sz, n_epochs, acc_freq, print_every)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m#now we pass batch through forward:\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_history\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(batch_X, batch_y))\n\u001b[0;32m--> 120\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackward(batch_y)\n\u001b[1;32m    121\u001b[0m iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n",
      "File \u001b[0;32m~/Documents/GitHub/CH343/project 3/network.py:299\u001b[0m, in \u001b[0;36mNetwork.backward\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    296\u001b[0m d_b \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers) :\n\u001b[0;32m--> 299\u001b[0m     d_upstream, d_wts, d_b \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mbackward(d_upstream, y)\n",
      "File \u001b[0;32m~/Documents/GitHub/CH343/project 3/layer.py:227\u001b[0m, in \u001b[0;36mLayer.backward\u001b[0;34m(self, d_upstream, y)\u001b[0m\n\u001b[1;32m    224\u001b[0m     d_upstream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_dlast_net_act()\n\u001b[1;32m    226\u001b[0m d_net_in \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward_netAct_to_netIn(d_upstream, y)\n\u001b[0;32m--> 227\u001b[0m dprev_net_ac, d_wts, d_b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackward_netIn_to_prevLayer_netAct(d_net_in)\n\u001b[1;32m    228\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_wts \u001b[39m=\u001b[39m d_wts\n\u001b[1;32m    229\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_b \u001b[39m=\u001b[39m d_b\n",
      "File \u001b[0;32m~/Documents/GitHub/CH343/project 3/layer.py:599\u001b[0m, in \u001b[0;36mConv2D.backward_netIn_to_prevLayer_netAct\u001b[0;34m(self, d_upstream)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(img_y):\n\u001b[1;32m    595\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(img_x):\n\u001b[1;32m    596\u001b[0m         \u001b[39m# When the filter is aligned with input position (x, y), accumulate\u001b[39;00m\n\u001b[1;32m    597\u001b[0m         \u001b[39m# the filter's weights – all globally weighted by the upstream gradient\u001b[39;00m\n\u001b[1;32m    598\u001b[0m         \u001b[39m# at the current (x, y) position.\u001b[39;00m\n\u001b[0;32m--> 599\u001b[0m         dprev_net_act[n, :, y:y\u001b[39m+\u001b[39mker_sz, x:x\u001b[39m+\u001b[39mker_sz] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m d_upstream[n, k, y, x] \u001b[39m*\u001b[39;49m kers[k]\n\u001b[1;32m    601\u001b[0m         \u001b[39m# Filter wts updated based on upstream change times inputs present in the filter\u001b[39;00m\n\u001b[1;32m    602\u001b[0m         \u001b[39m# (this amount of input made the output change this much)\u001b[39;00m\n\u001b[1;32m    603\u001b[0m         d_wts[k] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m d_upstream[n, k, y, x] \u001b[39m*\u001b[39m inputPadded[n, :, y:y\u001b[39m+\u001b[39mker_sz, x:x\u001b[39m+\u001b[39mker_sz]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "sgd_ConvNet4 = ConvNet4(input_shape = (3,16,16), wt_scale = 1e-2)\n",
    "sgd_ConvNet4.compile('sgd')\n",
    "sgd_ConvNet4.fit(x_dev, y_dev, x_val, y_val,acc_freq=10, print_every=10, mini_batch_sz = 20, n_epochs = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7d. Evaluate and plot the different optimizer results\n",
    "\n",
    "Make 2 \"high quality\" plots showing the following\n",
    "\n",
    "- Plot the accuracy (y axis) for the three optimizers as a function of training epoch (x axis).\n",
    "- Plot the loss (y axis) for the three optimizers as a function of training iteration (x axis).\n",
    "\n",
    "A high quality plot consists of:\n",
    "- A useful title\n",
    "- X and Y axis labels\n",
    "- A legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7e. Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: Why does decreasing the mini-batch size make the loss print-outs more erratic in Task 7c?\n",
    "\n",
    "**Question 5**: Which optimizer works best and why do think it is best?\n",
    "\n",
    "**Question 6**: What is happening with the training set accuracy and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 4:** \n",
    "\n",
    "**Answer 5:** \n",
    "\n",
    "**Answer 6:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Training your convolutional neural network on STL-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8a. Load in STL-10 at 32x32 resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images are: (5000, 96, 96, 3)\n",
      "Labels are: (5000,)\n",
      "Resizing 5000 images to 32x32...Done!\n",
      "Saving Numpy arrays the images and labels to ./numpy...Done!\n",
      "Train data shape:  (4398, 3, 32, 32)\n",
      "Train labels shape:  (4398,)\n",
      "Test data shape:  (400, 3, 32, 32)\n",
      "Test labels shape:  (400,)\n",
      "Validation data shape:  (200, 3, 32, 32)\n",
      "Validation labels shape:  (200,)\n",
      "dev data shape:  (2, 3, 32, 32)\n",
      "dev labels shape:  (2,)\n"
     ]
    }
   ],
   "source": [
    "# Download the STL-10 dataset from the internet, convert it to Numpy ndarray, resize to 16x16\n",
    "# cache it locally on your computer for faster loading next time.\n",
    "load_stl10_dataset.purge_cached_dataset()\n",
    "# preprocess and create splits\n",
    "x_train, y_train, x_test, y_test, x_val, y_val, x_dev, y_dev = preprocess_data.load_stl10(\n",
    "    n_train_samps=4398, n_test_samps=400, n_valid_samps=200, n_dev_samps=2, scale_fact=3)\n",
    "\n",
    "print ('Train data shape: ', x_train.shape)\n",
    "print ('Train labels shape: ', y_train.shape)\n",
    "print ('Test data shape: ', x_test.shape)\n",
    "print ('Test labels shape: ', y_test.shape)\n",
    "print ('Validation data shape: ', x_val.shape)\n",
    "print ('Validation labels shape: ', y_val.shape)\n",
    "print ('dev data shape: ', x_dev.shape)\n",
    "print ('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b. Set up accelerated convolution and max pooling layers\n",
    "\n",
    "As you may have noticed, we had to downsize STL-10 to 16x16 resolution to train the network on the dev set (N=20) in a reasonable amount of time. The training set has N≅4000 samples, how will we ever manage to process that amount of data?!\n",
    "\n",
    "On one hand, this is an unfortunate inevitable reality of working with large (\"big\") datasets: you can easily find a dataset that is too time consuming to process for any computer, despite how fast/many CPU/GPUs it has.\n",
    "\n",
    "On the other hand, we can do better for this project and STL-10 :) If you were to time (profile) different parts of the training process, you'd notice that largest bottleneck is convolution and max pooling operations (both forward/backward). You implemented those operations intuitively, which does not always yield the best performance. **By swapping out forward/backward convolution and maxpooling for implementations that use different algorithms (im2col, reshaping) that are compiled to C code, we will speed up training up by several orders of magnitude**.\n",
    "\n",
    "Follow these steps to subsitute in the \"accelerated\" convolution and max pooling layers.\n",
    "\n",
    "- Install the `cython` python package: `pip3 install cython`.\n",
    "- Dowload files `im2col_cython.pyx`, `accelerated_layer.py`, `setup.py` from the project website. Put them in your base project folder.\n",
    "- Open terminal, `cd` to Project directory.\n",
    "- Compile the im2col functions: `python3 setup.py build_ext --inplace`. A `.c` and `.so` file should have appeared in your project folder (*It is ok if it prints out a bunch of warnings. If it creates `.c` and `.so` files after a few seconds, you should be all set.*).\n",
    "- Restart Jupyter Notebook kernel\n",
    "- Create a class called `Conv4NetAccel` in `network.py` by copy-pasting the contents of `Conv4Net`. Import `accelerated_layer` at the top and replace the `Conv2D` and `MaxPooling2D` layers with `Conv2DAccel` and `MaxPooling2DAccel`.\n",
    "\n",
    "\n",
    "#### Windows users\n",
    "\n",
    "The above compile terminal command for Windows users is:\n",
    "\n",
    "```bash\n",
    "python setup.py build_ext --inplace\n",
    "```\n",
    "\n",
    "Before this can work though, you’ll need a C/C++ compiler installed on your system. To do this, download [Microsoft Build tools for Visual Studio 2019](https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools&rel=16). Click to download the installer. Run it and select the C++ compiler option. It might ask you to install other stuff, but that shouldn’t be necessary — just the C++ compiler. After it is installed, run the above python terminal command. It should end without error (last line should be “Finished generating code”). Warning printouts are fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8c. Training convolutional neural network on STL-10\n",
    "\n",
    "You are now ready to train on the entire training set.\n",
    "\n",
    "- Create a `Conv4NetAccel` object with hyperparameters of your choice.\n",
    "- Your goal is to achieve at least 45% accuracy on the test and/or validation set.\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- I suggest using your intuition about hyperparameters and over/underfitting to guide your choice, rather than a grid search. This should not be overly challenging.\n",
    "- Use the best / most efficient optimizer based on your prior analysis.\n",
    "- It should take on the order of 1 sec per training iteration. If that's way off, seek help as something could be wrong with running the acclerated code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ConvNet4Accel' from 'network' (/Users/gordondoore/Documents/GitHub/CH343/project 3/network.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetwork\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNet4Accel\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ConvNet4Accel' from 'network' (/Users/gordondoore/Documents/GitHub/CH343/project 3/network.py)"
     ]
    }
   ],
   "source": [
    "from network import ConvNet4Accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8d. Analysis of STL-10 training quality\n",
    "\n",
    "Use your trained network that achieves 45%+ accuracy on the test set to make \"high quality\" plots showing the following \n",
    "\n",
    "- Plot the accuracy of the training and validation sets as a function of training epoch. You may have to convert iterations to epochs.\n",
    "- Plot the loss as a function of training iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8e. Visualize layer weights\n",
    "\n",
    "Run the following code and submit the inline image of the weight visualization of the 1st layer (convolutional layer) of the network.\n",
    "\n",
    "**Note:**\n",
    "- Setting optional parameter to `True` will let you save a .PNG file in your project folder of your weights. I'd suggest setting it to `False` unless look at your weights and they look like they are worth saving. You don't want a training run that produces undesirable weights to overwrite your good looking results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(wts, saveFig=True, filename='convWts.png'):\n",
    "    grid_sz = int(np.sqrt(len(wts)))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for x in range(grid_sz):\n",
    "        for y in range(grid_sz):\n",
    "            lin_ind = np.ravel_multi_index((x, y), dims=(grid_sz, grid_sz))\n",
    "            plt.subplot(grid_sz, grid_sz, lin_ind+1)\n",
    "            currImg = wts[lin_ind]\n",
    "            low, high = np.min(currImg), np.max(currImg)\n",
    "            currImg = 255*(currImg - low) / (high - low)\n",
    "            currImg = currImg.astype('uint8')\n",
    "            plt.imshow(currImg)\n",
    "            plt.gca().axis('off')\n",
    "    plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "    if saveFig:\n",
    "        plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsitute your trained network below\n",
    "# netT is my network's name\n",
    "# Every weight should not look like RGB noise\n",
    "plot_weights(netT.layers[0].wts.transpose(0, 2, 3, 1), saveFig=True, filename='convWts_adam_train_20epoch.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8f. Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7:** What do the learned filters look like? Does this make sense to you / is this what you expected? In which area of the brain do these filters resemble cell receptive fields?\n",
    "\n",
    "#### Note\n",
    "\n",
    "You should not see RGB \"noise\". If you do, and you pass the \"overfit\" test with the Adam optimizer, you probably need to increase the number of training epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 7:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "**General advice:** When making modifications for extensions, make small changes, then check to make sure you pass test code. Also, test out the network runtime on small examples before/after the changes. If you're not careful, the simulation time can become intractable really quickly!\n",
    "\n",
    "**Remember:** One thorough extension usually is worth more than several \"shallow\" extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Pedal to the metal: achieve high accuracy on STL-10\n",
    "\n",
    "You can achieve higher (>50%) classification accuracy on the STL-10 test set. Find the hyperparameters to achieve this. You can use random or grid search — keep in mind that even with the accelerated layers, each training run will take at least minutes to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Experiment with different network architectures.\n",
    "\n",
    "The design of the `Network` class is modular. As long as you're careful about shapes, adding/removing network layers (e.g. `Conv2D`, `Dense`, etc.) should be straight forward. Experiment with adding another sequence of `Conv2D` and `MaxPooling2D` layers. Add another `Dense` hidden layer before the output layer. How do the changes affect classification accuracy and loss? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Experiment with different network hyperparameters.\n",
    "\n",
    "Explore the affect one or more change below has on classification. Be careful about how the hyperparameters may affect the shape of network layers. Thorough analysis will get you more points (not try a few ad hoc values).\n",
    "\n",
    "- Experiment with different numbers of hidden units in the Dense layers.\n",
    "- Experiment different max pooling window sizes and strides.\n",
    "- Experiment with kernel sizes (not 7x7). Can you get away with smaller ones? Do they perform just as well? What is the change in runtime like? What is the impact on their visualized appearance?\n",
    "- Experiment with number of kernels in the convolutional layer. Is more/fewer better? What is the impact on their visualized appearance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Different hidden layer activation functions\n",
    "\n",
    "Implement and experiment with activation functions that are appropriate for hidden layers (e.g. ELU, SELU, GELU, sigmoid, Softplus, Mish, etc.). How do they affect speed of training and accuracy? These activation functions can replace ReLU in Dense and Conv2D layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. Add and test some training bells and whistles\n",
    "\n",
    "Add features like early stopping, learning rate decay (learning rate at the end of an epoch becomes some fraction of its former value), etc and assess how they affect training loss convergence and accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Additional optimizers\n",
    "\n",
    "Research other optimizers used in backpropogation and implement one or more of them within the model structure. Compare its performance to ones you have implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Optimize your algorithms\n",
    "\n",
    "Find the main performance bottlenecks in the network and improve your code to reduce runtime (e.g. reduce explicit for loops, increase vectorization, etc). Research faster algorithms to do operations like convolution and implement them. Given the complexity of the network, I suggest focusing on one area at a time and make sure everything you change passes the test code before proceeding. Quantify and discuss your performance improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Additional loss functions\n",
    "\n",
    "Implement support for sigmoid, or another activation functions and associated losses. Test it out and compare with softmax/cross entropy. Make sure any necessary changes to the layer's gradient are made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Additional datasets\n",
    "\n",
    "Do classification and analyze the results with an image dataset of your choice (MNIST, Fashion MNIST, CIFAR10, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Performance analysis\n",
    "\n",
    "Do a thorough comparative analysis of the non-accelerated network and accelerated networks with respect to runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Visualize network predictions\n",
    "\n",
    "Plot predicted class labels with a sample of test images to better assess where the network excels and where it struggles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Confusion matrix\n",
    "\n",
    "Make a confusion matrix and analyze the pattern of errors made by the network. For example, does the network confuse any two classes far more than others?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
